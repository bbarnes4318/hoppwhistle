GOAL

Add a “Recording Analyzer” tool inside Hopwhistle that lets users paste recording URLs or upload mp3/wav, select a vertical + fields to extract, triggers existing transcription pipeline, then runs extraction (LLM via DeepSeek), stores results, and shows results in a polished UI page under Dashboard → Tools.

NON-NEGOTIABLES

Include every file fully. Do not say “already provided”.

Do NOT modify apps/media/transcriber/src/index.ts.

Use existing Redis stream events:stream and event types:

API publishes: recording.ready

Transcriber publishes: transcription.ready

Correlation ID must be: callId === RecordingAnalysis.id

A) PRISMA MODEL (apps/api)
File: apps/api/prisma/schema.prisma

Add this model anywhere among other models:

model RecordingAnalysis {
  id             String   @id @default(uuid())
  tenantId       String
  userId         String

  batchId        String
  vertical       String   // ACA | FINAL_EXPENSE | MEDICARE

  sourceType     String   // url | upload
  sourceUrl      String?
  storageKey     String?
  filename       String?

  selectedFields Json     // JSON array of strings

  status         String   // queued | transcribing | analyzing | done | failed
  transcript     String?
  extracted      Json?
  error          String?

  createdAt      DateTime @default(now())
  updatedAt      DateTime @updatedAt

  @@index([tenantId, batchId])
  @@index([tenantId, createdAt])
  @@index([status])
  @@map("recording_analysis")
}

Required commands:
cd apps/api
pnpm prisma migrate dev -n recording_analysis
pnpm prisma generate

B) STORAGE PRESIGN HELPER (apps/api)

We must NOT access private fields with as any. Add a real helper method.

File: apps/api/src/services/storage.js

Inside export class StorageService { ... } add this method:

  /**
   * Generate a presigned PUT URL (for browser direct uploads)
   */
  async createPresignedPutUrl(args: {
    storageKey: string;
    contentType: string;
    metadata?: Record<string, string>;
    expiresInSec?: number;
  }): Promise<string> {
    const { storageKey, contentType, metadata, expiresInSec } = args;

    const command = new PutObjectCommand({
      Bucket: this.bucket,
      Key: storageKey,
      ContentType: contentType || 'application/octet-stream',
      Metadata: metadata || {},
    });

    const url = await getSignedUrl(this.s3Client, command, { expiresIn: expiresInSec ?? 900 });
    return url;
  }


(Your file already imports PutObjectCommand and getSignedUrl, keep them.)

C) API ROUTES (apps/api)
C1) Presign route (uploads)
Create file: apps/api/src/routes/recording-analysis-upload.ts
import { Router } from 'express';
import crypto from 'crypto';

import { requireSession } from '../middleware/session';
import { rbac } from '../middleware/rbac';
import { getStorageService } from '../services/storage.js';

const router = Router();
router.use(requireSession);
router.use(rbac());

function guessExt(filename: string, contentType: string) {
  const lower = (filename || '').toLowerCase();
  if (lower.endsWith('.wav')) return 'wav';
  if (lower.endsWith('.mp3')) return 'mp3';
  if (lower.endsWith('.ogg')) return 'ogg';
  if (lower.endsWith('.opus')) return 'opus';
  if ((contentType || '').includes('wav')) return 'wav';
  if ((contentType || '').includes('mpeg') || (contentType || '').includes('mp3')) return 'mp3';
  if ((contentType || '').includes('ogg')) return 'ogg';
  if ((contentType || '').includes('opus')) return 'opus';
  return 'wav';
}

router.post('/presign', async (req, res) => {
  const tenantId = (req as any).session.tenantId as string;

  const { filename, contentType } = req.body ?? {};
  if (!filename) return res.status(400).json({ error: 'filename is required' });

  const ext = guessExt(filename, contentType || '');
  const date = new Date();
  const year = date.getFullYear();
  const month = String(date.getMonth() + 1).padStart(2, '0');
  const day = String(date.getDate()).padStart(2, '0');

  const random = crypto.randomUUID();
  const safeName = String(filename).replace(/[^\w.\-]+/g, '_').slice(0, 80);

  const storageKey = `recording-analyzer/${year}/${month}/${day}/${tenantId}/${random}-${safeName}.${ext}`;

  const storage = getStorageService();
  const url = await storage.createPresignedPutUrl({
    storageKey,
    contentType: contentType || 'application/octet-stream',
    metadata: {
      tenantId,
      source: 'recording-analyzer',
      originalFilename: safeName,
    },
    expiresInSec: 900,
  });

  return res.json({ storageKey, url });
});

export default router;

C2) Analyze route (creates jobs + publishes recording.ready)
Create file: apps/api/src/routes/recording-analysis.ts
import { Router } from 'express';
import crypto from 'crypto';

import { prisma } from '../lib/prisma';
import { requireSession } from '../middleware/session';
import { rbac } from '../middleware/rbac';
import { getRedisClient } from '../services/redis';
import { getStorageService } from '../services/storage.js';

const router = Router();
router.use(requireSession);
router.use(rbac());

type UploadRef = { storageKey: string; filename?: string };

router.post('/analyze', async (req, res) => {
  const tenantId = (req as any).session.tenantId as string;
  const userId = (req as any).session.userId as string;

  const { vertical, selectedFields, urls = [], uploads = [] } = req.body ?? {};

  if (!vertical) return res.status(400).json({ error: 'vertical is required' });
  if (!Array.isArray(selectedFields)) return res.status(400).json({ error: 'selectedFields must be an array' });

  const redis = getRedisClient();
  const storage = getStorageService();
  const batchId = crypto.randomUUID();
  const jobIds: string[] = [];

  // URL jobs
  for (const url of (urls as string[])) {
    if (!url || typeof url !== 'string') continue;

    const row = await prisma.recordingAnalysis.create({
      data: {
        tenantId,
        userId,
        batchId,
        vertical,
        selectedFields,
        sourceType: 'url',
        sourceUrl: url,
        status: 'queued',
      },
      select: { id: true },
    });

    jobIds.push(row.id);

    await redis.xadd(
      'events:stream',
      '*',
      'channel',
      'recording.*',
      'payload',
      JSON.stringify({
        event: 'recording.ready',
        tenantId,
        data: { callId: row.id, recordingUrl: url, durationSec: 0 },
      })
    );

    await prisma.recordingAnalysis.update({
      where: { id: row.id },
      data: { status: 'transcribing' },
    });
  }

  // Upload jobs
  for (const up of (uploads as UploadRef[])) {
    if (!up?.storageKey) continue;

    const signedUrl = await storage.getSignedUrl(up.storageKey, 86400);

    const row = await prisma.recordingAnalysis.create({
      data: {
        tenantId,
        userId,
        batchId,
        vertical,
        selectedFields,
        sourceType: 'upload',
        storageKey: up.storageKey,
        filename: up.filename ?? null,
        status: 'queued',
      },
      select: { id: true },
    });

    jobIds.push(row.id);

    await redis.xadd(
      'events:stream',
      '*',
      'channel',
      'recording.*',
      'payload',
      JSON.stringify({
        event: 'recording.ready',
        tenantId,
        data: { callId: row.id, recordingUrl: signedUrl, durationSec: 0 },
      })
    );

    await prisma.recordingAnalysis.update({
      where: { id: row.id },
      data: { status: 'transcribing' },
    });
  }

  return res.json({ batchId, jobIds });
});

router.get('/batch/:batchId', async (req, res) => {
  const tenantId = (req as any).session.tenantId as string;
  const batchId = req.params.batchId;

  const items = await prisma.recordingAnalysis.findMany({
    where: { tenantId, batchId },
    orderBy: { createdAt: 'asc' },
  });

  return res.json({ batchId, items });
});

export default router;

C3) Register routes
File: apps/api/src/routes/index.ts

Add imports + mounts:

import recordingAnalysis from './recording-analysis';
import recordingAnalysisUpload from './recording-analysis-upload';

router.use('/recording-analysis', recordingAnalysis);
router.use('/recording-analysis', recordingAnalysisUpload);


Endpoints:

POST /api/recording-analysis/analyze

GET /api/recording-analysis/batch/:batchId

POST /api/recording-analysis/presign

D) TRANSCRIBER CHANGE (apps/media/transcriber) — REQUIRED

This is REQUIRED so analysis worker does not depend on a DB table you’re not actually writing.

File: apps/media/transcriber/src/worker.ts

In processResult() where you build transcriptionEvent, add fullText and segments in the event payload.

Find this block (you pasted it):

const transcriptionEvent: TranscriptionReadyEvent = {
  event: 'transcription.ready',
  tenantId: result.tenantId,
  data: {
    callId: result.callId,
    transcriptId,
    stats,
  },
};


Replace with:

const transcriptionEvent: any = {
  event: 'transcription.ready',
  tenantId: result.tenantId,
  data: {
    callId: result.callId,
    transcriptId,
    stats,
    fullText: result.fullText || '',
    segments: result.segments || [],
    language: result.language || 'en',
    durationSec: result.durationSec || 0,
    engine: result.engine || null,
  },
};


Do NOT touch apps/media/transcriber/src/index.ts.

E) WORKER (apps/worker) — WITH ALL 4 UPGRADES
E1) Local Redis helper (DO NOT import from apps/api)
Create file: apps/worker/src/services/redis.ts
import Redis from 'ioredis';

let redisClient: Redis | null = null;

export function getRedisClient(): Redis {
  if (!redisClient) {
    const redisUrl = process.env.REDIS_URL || 'redis://localhost:6379';
    redisClient = new Redis(redisUrl, {
      maxRetriesPerRequest: 3,
      retryStrategy: (times) => {
        const delay = Math.min(times * 50, 2000);
        return delay;
      },
    });

    redisClient.on('error', (err) => {
      // eslint-disable-next-line no-console
      console.error('Redis Client Error:', err);
    });

    redisClient.on('connect', () => {
      // eslint-disable-next-line no-console
      console.log('✅ Redis connected (worker)');
    });
  }

  return redisClient;
}

export async function closeRedisClient(): Promise<void> {
  if (redisClient) {
    await redisClient.quit();
    redisClient = null;
  }
}

E2) Install dependency (schema validation)

Worker needs Zod:

cd apps/worker
pnpm add zod

E3) Recording Analysis Worker (DeepSeek + Schema Validation + Confidence + Billable Logic + Vertical Prompting)
Create file: apps/worker/src/services/recording-analysis-worker.ts
import { PrismaClient } from '@prisma/client';
import { z } from 'zod';
import { getRedisClient } from './redis';

const prisma = new PrismaClient();

type TranscriptionReadyEvent = {
  event: 'transcription.ready';
  tenantId: string;
  data: {
    callId: string; // MUST be RecordingAnalysis.id
    transcriptId?: string;
    stats?: any;
    fullText?: string;
    segments?: any[];
    language?: string;
    durationSec?: number;
    engine?: string;
  };
};

type Vertical = 'ACA' | 'FINAL_EXPENSE' | 'MEDICARE';

type ExtractedPayload = {
  values: Record<string, any>;
  confidence: Record<string, number>; // 0..1 per field
  overallConfidence: number; // 0..1
  billable?: 'Y' | 'N';
  nonbillable_reason?: string | null;
};

/** ------------------- DeepSeek call (strict JSON) ------------------- */
async function callDeepSeekStrictJson(prompt: string): Promise<any> {
  const endpoint = process.env.DEEPSEEK_ENDPOINT || 'https://api.deepseek.com/chat/completions';
  const apiKey = process.env.DEEPSEEK_API_KEY;
  const model = process.env.DEEPSEEK_MODEL || 'deepseek-chat';

  if (!apiKey) throw new Error('DEEPSEEK_API_KEY is not set');

  const r = await fetch(endpoint, {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model,
      temperature: 0.1,
      max_tokens: 1200,
      messages: [
        {
          role: 'system',
          content:
            'Return ONLY valid JSON. No markdown. No commentary. ' +
            'If unsure, return null values and lower confidence.',
        },
        { role: 'user', content: prompt },
      ],
    }),
  });

  if (!r.ok) {
    const t = await r.text();
    throw new Error(`DeepSeek HTTP ${r.status}: ${t}`);
  }

  const j: any = await r.json();
  const content = j?.choices?.[0]?.message?.content;
  if (!content || typeof content !== 'string') throw new Error('DeepSeek empty content');

  const trimmed = content.trim();

  if (trimmed.startsWith('```')) {
    const cleaned = trimmed
      .replace(/^```json/i, '')
      .replace(/^```/i, '')
      .replace(/```$/, '')
      .trim();
    return JSON.parse(cleaned);
  }

  return JSON.parse(trimmed);
}

/** ------------------- Field schemas (dynamic) ------------------- */
const NUM = z.number().finite().nullable();
const STR = z.string().min(1).nullable();
const YESNO = z.enum(['Y', 'N']).nullable();

function schemaForField(field: string) {
  const f = field.toLowerCase();

  if (f.includes('applications')) return z.number().int().min(0).nullable();
  if (f.includes('enrollments')) return z.number().int().min(0).nullable();
  if (f === 'quotes') return z.number().int().min(0).nullable();
  if (f.includes('follow-ups') || f.includes('follow ups')) return z.number().int().min(0).nullable();

  if (f.includes('monthly premium')) return NUM;
  if (f.startsWith('carrier')) return STR;

  if (f === 'billable' || f.includes('billable')) return YESNO;
  if (f.startsWith('reason')) return z.string().nullable();
  if (f.includes('transcript')) return z.string().nullable();

  // default: allow null/primitive
  return z.any().nullable();
}

function buildDynamicSchema(selectedFields: string[]) {
  const valuesShape: Record<string, z.ZodTypeAny> = {};
  const confShape: Record<string, z.ZodTypeAny> = {};

  for (const key of selectedFields) {
    valuesShape[key] = schemaForField(key);
    confShape[key] = z.number().min(0).max(1).nullable().default(null);
  }

  return z.object({
    values: z.object(valuesShape),
    confidence: z.object(confShape),
    overallConfidence: z.number().min(0).max(1).default(0.5),
    billable: z.enum(['Y', 'N']).optional(),
    nonbillable_reason: z.string().nullable().optional(),
  });
}

/** ------------------- Vertical-specific prompt tuning ------------------- */
function buildPrompt(vertical: Vertical, selectedFields: string[], transcript: string) {
  const baseRules = [
    'Return ONLY JSON. No markdown. No extra text.',
    'Output format MUST be:',
    '{ "values": { ... }, "confidence": { ... }, "overallConfidence": 0.0-1.0, "billable":"Y|N", "nonbillable_reason": string|null }',
    '',
    'Rules:',
    '- values must include ONLY the selected field keys.',
    '- confidence must include the same keys with 0..1 (use 0.2 if guessing).',
    '- overallConfidence is 0..1.',
    '- Billable must be Y or N.',
    '- If Billable is N, nonbillable_reason must be a short string.',
    '- If a value is not present, use null (or 0 for counts).',
  ];

  const verticalGuidance =
    vertical === 'FINAL_EXPENSE'
      ? [
          'FINAL EXPENSE GUIDANCE:',
          '- Applications Submitted: count submitted applications.',
          '- Monthly Premium fields: numeric premium if explicitly stated, else null.',
          '- Carrier: carrier name if explicitly stated, else null.',
          '- Quotes: count distinct quotes presented.',
          '- Follow-Ups: count clear follow-up actions.',
          '- Billable should be Y only if there was a meaningful sales outcome (quote or app) AND caller intent was real.',
        ]
      : vertical === 'ACA'
      ? [
          'ACA GUIDANCE:',
          '- Enrollments: count completed enrollments (confirmed submitted).',
          '- Carrier: carrier name if enrollment occurred.',
          '- Billable: Y if enrollment completed OR strong qualified transfer intent; otherwise N.',
        ]
      : [
          'MEDICARE GUIDANCE:',
          '- Enrollments: count completed enrollments or completed plan switches.',
          '- Carrier: carrier name if known and stated.',
          '- Billable: Y if enrollment completed OR clearly qualified conversion intent; otherwise N.',
        ];

  return [
    ...baseRules,
    '',
    `VERTICAL: ${vertical}`,
    `SELECTED_FIELDS: ${selectedFields.join(' | ')}`,
    '',
    ...verticalGuidance,
    '',
    'Transcript:',
    transcript,
  ].join('\n');
}

/** ------------------- Billable hard-logic (deterministic) ------------------- */
function enforceBillableHardLogic(vertical: Vertical, values: Record<string, any>) {
  const getNum = (k: string) => {
    const v = values?.[k];
    if (typeof v === 'number' && Number.isFinite(v)) return v;
    return null;
  };
  const getStr = (k: string) => {
    const v = values?.[k];
    if (typeof v === 'string' && v.trim()) return v.trim();
    return null;
  };

  // Common signals
  const apps = getNum('Applications Submitted');
  const quotes = getNum('Quotes');
  const enroll = getNum('Enrollments');

  const premiumApp =
    getNum('Monthly Premium (if app submitted)') ??
    getNum('Monthly Premium (If Quote Provided)');

  const carrierApp =
    getStr('Carrier (If app submitted)') ??
    getStr('Carrier (If Quote Provided)') ??
    getStr('Carrier (If enrollment)');

  let billable: 'Y' | 'N' = 'N';
  let reason: string | null = 'No qualifying outcome detected.';

  if (vertical === 'FINAL_EXPENSE') {
    const hasOutcome = (apps ?? 0) > 0 || (quotes ?? 0) > 0;
    if (hasOutcome) {
      billable = 'Y';
      reason = null;

      // tighten: if app submitted but no premium/carrier at all, still billable but confidence should be lower (handled by model)
      if ((apps ?? 0) > 0 && !premiumApp && !carrierApp) {
        // still allow, but reason null
      }
    }
  } else {
    const hasOutcome = (enroll ?? 0) > 0;
    if (hasOutcome) {
      billable = 'Y';
      reason = null;
    }
  }

  return { billable, nonbillable_reason: reason };
}

/** ------------------- Main worker ------------------- */
export async function startRecordingAnalysisWorker() {
  const redis = getRedisClient();

  try {
    await redis.xgroup('CREATE', 'events:stream', 'recording-analysis-group', '0', 'MKSTREAM');
  } catch {}

  while (true) {
    const messages = await redis.xreadgroup(
      'GROUP',
      'recording-analysis-group',
      'recording-analysis-worker',
      'COUNT',
      '5',
      'BLOCK',
      '1000',
      'STREAMS',
      'events:stream',
      '>'
    );

    if (!messages?.length) continue;

    const [, streamMessages] = messages[0] as any;

    for (const [messageId, fields] of streamMessages) {
      let callId: string | null = null;

      try {
        const fieldMap: Record<string, string> = {};
        for (let i = 0; i < fields.length; i += 2) fieldMap[fields[i]] = fields[i + 1];

        const payload = JSON.parse(fieldMap.payload || '{}') as TranscriptionReadyEvent;

        if (payload.event !== 'transcription.ready') {
          await redis.xack('events:stream', 'recording-analysis-group', messageId);
          continue;
        }

        callId = payload.data?.callId || null;
        if (!callId) {
          await redis.xack('events:stream', 'recording-analysis-group', messageId);
          continue;
        }

        const row = await prisma.recordingAnalysis.findUnique({ where: { id: callId } });
        if (!row) {
          await redis.xack('events:stream', 'recording-analysis-group', messageId);
          continue;
        }

        // Idempotency: if already done/failed, ack + skip
        const s0 = String(row.status || '').toLowerCase();
        if (s0 === 'done' || s0 === 'failed') {
          await redis.xack('events:stream', 'recording-analysis-group', messageId);
          continue;
        }

        await prisma.recordingAnalysis.update({
          where: { id: callId },
          data: { status: 'analyzing', error: null },
        });

        const selectedFields = Array.isArray(row.selectedFields) ? (row.selectedFields as any as string[]) : [];

        const transcriptText = (payload.data.fullText || '').trim();
        if (!transcriptText) throw new Error('transcription.ready did not include fullText (required).');

        const vertical = row.vertical as Vertical;

        const prompt = buildPrompt(vertical, selectedFields, transcriptText);

        const raw = await callDeepSeekStrictJson(prompt);

        // Validate / coerce to schema
        const schema = buildDynamicSchema(selectedFields);
        const parsed = schema.safeParse(raw);

        if (!parsed.success) {
          throw new Error('LLM JSON failed schema validation: ' + parsed.error.message);
        }

        const extracted = parsed.data as ExtractedPayload;

        // Billable hard-logic override (deterministic)
        const enforced = enforceBillableHardLogic(vertical, extracted.values);

        extracted.billable = enforced.billable;
        extracted.nonbillable_reason = enforced.nonbillable_reason;

        // Only store transcript if selectedFields includes transcript
        const wantsTranscript = selectedFields.some((k) => k.toLowerCase().includes('transcript'));

        await prisma.recordingAnalysis.update({
          where: { id: callId },
          data: {
            status: 'done',
            transcript: wantsTranscript ? transcriptText : null,
            extracted,
            error: null,
          },
        });

        await redis.xack('events:stream', 'recording-analysis-group', messageId);
      } catch (e: any) {
        await redis.xack('events:stream', 'recording-analysis-group', messageId);

        // Best-effort failure update
        if (callId) {
          try {
            await prisma.recordingAnalysis.update({
              where: { id: callId },
              data: {
                status: 'failed',
                error: e?.message || 'Unknown error',
              },
            });
          } catch {}
        }
      }
    }
  }
}

E4) Start the worker
File: apps/worker/src/index.ts

Add:

import { startRecordingAnalysisWorker } from './services/recording-analysis-worker';

void startRecordingAnalysisWorker();

Worker ENV (required)

Make sure worker has:

DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxxx
DEEPSEEK_ENDPOINT=https://api.deepseek.com/chat/completions
DEEPSEEK_MODEL=deepseek-chat
REDIS_URL=redis://localhost:6379
DATABASE_URL=postgresql://..